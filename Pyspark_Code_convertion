import subprocess
from pyspark.sql.functions import *
from pyspark.sql import functions as f
from operator import add
from pyspark.sql import Row, SparkSession
from pyspark.sql.types import StructField, StringType, StructType

def sparkwithhiveone():
    sparkwithhive = getsparkwithhive()
    try:
        assert (sparkwithhive.conf.get("spark.sql.catalogImplementation") == "hive")
        sparkwithhive.sql("DROP TABLE IF EXISTS table_a")
        sparkwithhive.sql("CREATE TABLE IF EXISTS table_a")
        sparkwithhive.sql("DROP TABLE IF EXISTS table_a")
        sparkwithhive.sql("CREATE TABLE IF EXISTS table_a")
        sparkwithhive.sql("DROP TABLE IF EXISTS table_a")
        sparkwithhive.sql("CREATE TABLE IF EXISTS table_a")
        sparkwithhive.sql("DROP TABLE IF EXISTS table_a")
        sparkwithhive.sql("CREATE TABLE IF EXISTS table_a")
        df1= sparkwithhive.sql("SELECT COUNT(*) FROM table_a").collect()[0][0]
        df2= sparkwithhive.sql("SELECT COUNT(*) FROM table_b").collect()[0][0]
        
        if (df1==df2);
            sparkwithhive.sql("SELECT COUNT(*) FROM table_a").collect()[0][0]
            sparkwithhive.sql("SELECT COUNT(*) FROM table_b").collect()[0][0]
        else : print("count mismatch in above table")
    except Exception as e:
        print("Unexpected error:", e)
        raise
    finally:
        sparkwithhive.stop()
        print("finally block")


def getsparkwithhive():
    sparkwithhive = SparkSession.builder \
        .master("spark://lnx2517.ch3.prod.i.com:7077") \
        .config("spark.sql.hive.metastore.version", "2.3.9") \
        .config("spark.sql.warehouse.dir", "hdfs://lnx2517.ch3.prod.i.com:9000/user/hive/warehouse") \
        .config("spark.sql.hive.metastore.jars", "/opt/apache-hive-2.3.9-bin/lib/*") \
        .config("spark.sql.catalogImplementation=hive") \
        .enableHiveSupport().getOrCreate()
    return sparkwithhive

def getspark():
    sparkobj: SparkSession = SparkSession.builder \
        .master("spark://lnx2517.ch3.prod.i.com:7077") \
        .getOrCreate()
    return sparkobj
if __name__ == '__main__':
    sparkwithhiveobj = getsparkwithhive()
    sparkwithhiveone()
    #spark = getspark()
    sparkwithhiveobj.stop()
